{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT for Text Generation: Text Completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Text Completion\n",
    "\n",
    "In this notebook, you will learn how to use OpenAI’s GPT models to generate text completions. Text completion is a common use case for GPT models, where you provide a prompt, and the model completes it based on the context of the prompt.\n",
    "\n",
    "GPT models are excellent at tasks such as:\n",
    "- Writing essays or articles\n",
    "- Answering questions\n",
    "- Creating dialogue for chatbots\n",
    "- Generating creative writing\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- Understand how to generate text completions using GPT.\n",
    "- Experiment with various parameters to control the quality and creativity of the completions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Your Environment\n",
    "\n",
    "Before we start, make sure you have the OpenAI Python library installed. You can install it using the following command:\n",
    "\n",
    "```bash\n",
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Set your API key here\n",
    "client = OpenAI(api_key=\"your-api-key-here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Text Completion Example (GPT-3.5)\n",
    "\n",
    "## Let's start by generating a simple text completion using GPT-3.5. We'll provide a prompt and allow the model to complete it.\n",
    "\n",
    "```python\n",
    "from openai import OpenAI\n",
    "\n",
    "# Set your API key\n",
    "client = OpenAI(api_key=\"your-api-key-here\")\n",
    "\n",
    "# Generate a completion using GPT-3.5\n",
    "response = client.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",              # Use GPT-3.5 model\n",
    "    prompt=\"Once upon a time, in a land far away,\",  # Prompt to complete\n",
    "    max_tokens=100,                     # Maximum number of tokens to generate\n",
    "    temperature=0.7                     # Controls creativity (0.7 is a good balance)\n",
    ")\n",
    "\n",
    "# Print the generated completion\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a completion using GPT-3.5\n",
    "response = client.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",              # Use GPT-3.5 model\n",
    "    prompt=\"Once upon a time, in a land far away,\",  # Prompt to complete\n",
    "    max_tokens=100,                     # Maximum number of tokens to generate\n",
    "    temperature=0.7                     # Controls creativity (0.7 is a good balance)\n",
    ")\n",
    "\n",
    "# Print the generated completion\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Simple Text Completion Example (GPT-4 Chat Completion):**\n",
    "\n",
    "For GPT-4, we use the `client.chat.completions.create` method with the `messages` parameter instead of `prompt`. \n",
    "\n",
    "The `messages` parameter expects a list of dictionaries, where each message specifies the role (`\"system\"`, `\"user\"`, or `\"assistant\"`) and content.\n",
    "\n",
    "Here’s an example:\n",
    "\n",
    "```python\n",
    "from openai import OpenAI\n",
    "\n",
    "# Set your API key\n",
    "client = OpenAI(api_key=\"your-api-key-here\")\n",
    "\n",
    "# Generate a chat-based completion using GPT-4\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",                      # Use GPT-4 chat model\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Tell me a story about a brave knight.\"}\n",
    "    ],\n",
    "    max_tokens=150,\n",
    "    temperature=0.7                     # Controls creativity\n",
    ")\n",
    "\n",
    "# Print the generated completion\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",                      # Use GPT-4 chat model\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Tell me a story about a brave knight.\"}\n",
    "    ],\n",
    "    max_tokens=150,\n",
    "    temperature=0.7                     # Controls creativity\n",
    ")\n",
    "\n",
    "# Print the generated completion\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Exploring Parameters for Text Completion:**\n",
    "\n",
    "OpenAI’s API provides various parameters to customize the text completion. Let’s explore some of the key parameters:\n",
    "\n",
    "- **`temperature`**: Controls randomness. Lower values like `0.2` make the output more focused and deterministic, while higher values like `0.8` produce more creative or random responses.\n",
    "- **`max_tokens`**: Limits the number of tokens in the completion. Higher values will produce longer completions.\n",
    "- **`top_p`**: Controls diversity via nucleus sampling. Setting `top_p=0.9` means only the top 90% probability mass is considered for generation.\n",
    "\n",
    "Let’s see how changing these parameters affects the output:\n",
    "\n",
    "```python\n",
    "# Experimenting with parameters\n",
    "response = client.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    prompt=\"In the future, artificial intelligence will\",\n",
    "    max_tokens=50,\n",
    "    temperature=0.9,  # More creative output\n",
    "    top_p=0.85        # Nucleus sampling\n",
    ")\n",
    "\n",
    "# Print the completion with custom parameters\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimenting with parameters\n",
    "response = client.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    prompt=\"In the future, artificial intelligence will\",\n",
    "    max_tokens=50,\n",
    "    temperature=0.9,  # More creative output\n",
    "    top_p=0.85        # Nucleus sampling\n",
    ")\n",
    "\n",
    "# Print the completion with custom parameters\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Use Cases for Text Completion:**\n",
    "\n",
    "Text completion can be used in a variety of scenarios. Let’s explore a few:\n",
    "\n",
    "### 1. **Creative Writing**:\n",
    "Generate stories, poems, or song lyrics by providing the model with a creative prompt.\n",
    "\n",
    "```python\n",
    "response = client.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    prompt=\"Write a poem about the ocean:\",\n",
    "    max_tokens=50,\n",
    "    temperature=0.9\n",
    ")\n",
    "\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    prompt=\"Write a poem about the ocean:\",\n",
    "    max_tokens=50,\n",
    "    temperature=0.9\n",
    ")\n",
    "\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. **Answering Questions**:\n",
    "\n",
    "Use the model to answer factual or creative questions.\n",
    "\n",
    "```python\n",
    "response = client.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    prompt=\"What are the key benefits of renewable energy?\",\n",
    "    max_tokens=50,\n",
    "    temperature=0.3  # Lower temperature for more focused response\n",
    ")\n",
    "\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    prompt=\"What are the key benefits of renewable energy?\",\n",
    "    max_tokens=50,\n",
    "    temperature=0.3  # Lower temperature for more focused response\n",
    ")\n",
    "\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. **Dialogue Generation**:\n",
    "\n",
    "Generate conversational dialogue for a chatbot or fictional characters using GPT-4.\n",
    "\n",
    "```python\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a friendly assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"How was your day?\"}\n",
    "    ],\n",
    "    max_tokens=50,\n",
    "    temperature=0.8\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a friendly assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"How was your day?\"}\n",
    "    ],\n",
    "    max_tokens=50,\n",
    "    temperature=0.8\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Explore these examples and think of your own use cases for text completion.**\n",
    "\n",
    "\n",
    "## Conclusion and Next Steps\n",
    "\n",
    "In this notebook, we explored:\n",
    "- How to generate simple text completions using GPT-3.5 and GPT-4.\n",
    "- How to customize text completions using parameters like `temperature`, `max_tokens`, and `top_p`.\n",
    "- Several real-world use cases for text completion.\n",
    "\n",
    "Next, you will dive into more advanced features of GPT for tasks such as summarization and translation.\n",
    "\n",
    "[Proceed to the next notebook: Summarization and Translation](../02-Summarization-and-Translation.ipynb)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
